# ResNet50 From Scratch -- Imagenette Classification (PyTorch)

This project implements a **fully custom ResNet-50 architecture from scratch** using **PyTorch**, trained and evaluated on the **Imagenette** dataset.
The goal is to build and train a high-performance convolutional neural network **without relying on torchvision's ResNet implementation**, showcasing full understanding of CNN architecture design, training engineering, and deep learning best practices.

## ğŸš€ Project Highlights

### ğŸ§  Custom ResNet50 Implementation

A complete ResNet-50 replication including: - Conv1 stem (7Ã—7 + MaxPool) - 4 stages of Bottleneck blocks: 3, 4, 6, 3 - Identity &
projection skip connections - AdaptiveAvgPool - Dynamic fully-connected classifier head

## ğŸ¨ Advanced Data Augmentation

Using Albumentations: - Resize to 224Ã—224 - Random rotation (Â±15Â°) - Horizontal & vertical flips - Normalization - ToTensorV2

## âš™ï¸ Training Pipeline

-   Mixed precision (`torch.amp.GradScaler`)
-   Adam + weight decay
-   Label smoothing (0.1)
-   ReduceLROnPlateau scheduler
-   Checkpointing
-   Softmax accuracy evaluation
-   TQDM progress bars

## ğŸ“‚ Project Structure

    dataset.py
    model.py
    train.py
    utils.py
    README.md

## ğŸ§© Model Architecture Summary

### Bottleneck Block

-   1Ã—1 â†’ 3Ã—3 â†’ 1Ã—1 convs
-   BatchNorm + ReLU
-   Identity / projection skip

### Dynamic Classifier

Input dim inferred at first forward pass.

## ğŸ‹ï¸ Training

    python train.py

## ğŸ“Š Performance

High accuracy on Imagenette using augmentations + label smoothing + LR scheduling.

## ğŸ”§ Requirements

    torch
    torchvision
    albumentations
    tqdm

## ğŸ§  Demonstrated Skills

-   Custom deep learning architecture engineering
-   PyTorch internals
-   Data augmentation pipelines
-   Training optimization techniques
-   Model evaluation & debugging

## ğŸš€ Future Improvements

-   MixUp/CutMix
-   Cosine Annealing
-   EMA weights
-   TensorBoard
-   ONNX export
